{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_shape: (1953,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# coding: utf-8\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import numpy as np\n",
    "import random\n",
    "import csv\n",
    "\n",
    "data = []\n",
    "output=[]\n",
    "\n",
    "with open('data.csv','r') as f:\n",
    "    csvreader = csv.DictReader(f)\n",
    "    for item in csvreader:\n",
    "        data.append([ item['DATE'], item['AUTHOR'], item['CONTENT'] ])\n",
    "        output.append(item['CLASS'])\n",
    "\n",
    "# The elements of the 'data' array: ['date string', 'author', 'comment', 'class label ('0': not spam, '1': spam)']\n",
    "        \n",
    "data = np.asarray(data)\n",
    "y=np.array(output)\n",
    "print('y_shape:',y.shape) #target size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max_length 1241\n"
     ]
    }
   ],
   "source": [
    "#data prepation for training\n",
    "# I created one-hot vector representations for data\n",
    "XX=[]\n",
    "max_len=10 #\n",
    "import numpy as np\n",
    "for i in range(len(data)):\n",
    "    z=(data[i,0]+' '+data[i,1]+' '+data[i,2]).lower().encode('utf-8') # I want to join matrix colums\n",
    "    a=len(z)\n",
    "    if max_len<a:\n",
    "        max_len=a\n",
    "    XX.append(z)\n",
    "\n",
    "print('Max_length', max_len)    #maximal length of line\n",
    "\n",
    "num_data=len(XX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length_chars:  165\n"
     ]
    }
   ],
   "source": [
    "b=set()\n",
    "for i in range(1953):\n",
    "    b=b | set(XX[i])\n",
    "\n",
    "chars=sorted(list(b))\n",
    "\n",
    "\n",
    "len_chars=len(chars)\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "\n",
    "print ('length_chars: ',len_chars)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1953, 204765)\n"
     ]
    }
   ],
   "source": [
    "#one-hot vector\n",
    "\n",
    "X = np.zeros((num_data,max_len,len_chars),dtype=np.bool)\n",
    "for i, sentence in enumerate(XX):\n",
    "    for t, char in enumerate(sentence):\n",
    "        X[i, t, char_indices[char]] = 1\n",
    "       \n",
    "\n",
    "X=X.reshape(num_data,max_len*len_chars)\n",
    "\n",
    "\n",
    "print(X.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_tarin:  (1367, 204765)\n",
      "y_train:  (1367,)\n",
      "X_test:  (586, 204765)\n",
      "y_test:  (586,)\n"
     ]
    }
   ],
   "source": [
    "#split data into train and test data \n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "print('X_tarin: ',X_train.shape)\n",
    "print('y_train: ', y_train.shape)\n",
    "print('X_test: ',X_test.shape)\n",
    "print('y_test: ',y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[233  44]\n",
      " [ 63 246]]\n"
     ]
    }
   ],
   "source": [
    "#I have 2 classes: 1 and 0; I used Logistic regression\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "predicted = model.predict(X_test)\n",
    "matrix = confusion_matrix(y_test, predicted)\n",
    "print(matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      0.84      0.81       277\n",
      "          1       0.85      0.80      0.82       309\n",
      "\n",
      "avg / total       0.82      0.82      0.82       586\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Calculation of Precision,Recall, F1-Score\n",
    "report = classification_report(y_test, predicted)\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accurancy:  0.817406143345\n"
     ]
    }
   ],
   "source": [
    "print ('Accurancy: ',metrics.accuracy_score(y_test, predicted))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
